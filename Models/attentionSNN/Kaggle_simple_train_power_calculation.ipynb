{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f4963",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install eco2ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9861d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/attentionSNN/pytorch/attentionSNN/1')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import SemanticSegmentationTarget\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from simple_utils import (\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    "    get_loaders,\n",
    "    check_accuracy,\n",
    "    save_predictions_as_imgs,\n",
    "    summarize_eco2ai_log,\n",
    "    )\n",
    "\n",
    "import resnet_2\n",
    "\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from eco2ai import Tracker\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1365694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet_2.resnet34().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb2fcd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "        Snn_Conv2d-1      [32, 2, 64, 128, 128]           3,136\n",
      "      BatchNorm3d1-2      [32, 64, 1, 128, 128]             128\n",
      "     batch_norm_2d-3      [32, 2, 64, 128, 128]               0\n",
      "        mem_update-4      [32, 2, 64, 128, 128]               0\n",
      "        Snn_Conv2d-5        [32, 2, 64, 64, 64]          36,864\n",
      "      BatchNorm3d1-6        [32, 64, 1, 64, 64]             128\n",
      "     batch_norm_2d-7        [32, 2, 64, 64, 64]               0\n",
      "        mem_update-8        [32, 2, 64, 64, 64]               0\n",
      "        Snn_Conv2d-9        [32, 2, 64, 64, 64]          36,864\n",
      "     BatchNorm3d2-10        [32, 64, 1, 64, 64]             128\n",
      "   batch_norm_2d1-11        [32, 2, 64, 64, 64]               0\n",
      "AdaptiveAvgPool3d-12          [32, 64, 1, 1, 1]               0\n",
      "           Conv3d-13           [32, 8, 1, 1, 1]             512\n",
      "             ReLU-14           [32, 8, 1, 1, 1]               0\n",
      "           Conv3d-15          [32, 64, 1, 1, 1]             512\n",
      "AdaptiveMaxPool3d-16          [32, 64, 1, 1, 1]               0\n",
      "           Conv3d-17           [32, 8, 1, 1, 1]             512\n",
      "             ReLU-18           [32, 8, 1, 1, 1]               0\n",
      "           Conv3d-19          [32, 64, 1, 1, 1]             512\n",
      "          Sigmoid-20          [32, 64, 1, 1, 1]               0\n",
      " ChannelAttention-21          [32, 1, 64, 1, 1]               0\n",
      "           Conv2d-22            [32, 1, 64, 64]              18\n",
      "          Sigmoid-23         [32, 1, 1, 64, 64]               0\n",
      " SpatialAttention-24         [32, 1, 1, 64, 64]               0\n",
      "             ReLU-25        [32, 1, 64, 64, 64]               0\n",
      "              CSA-26        [32, 1, 64, 64, 64]               0\n",
      "      PruningCell-27        [32, 2, 64, 64, 64]               0\n",
      "        AvgPool3d-28        [32, 2, 64, 64, 64]               0\n",
      "       Snn_Conv2d-29        [32, 2, 64, 64, 64]           4,096\n",
      "     BatchNorm3d1-30        [32, 64, 1, 64, 64]             128\n",
      "    batch_norm_2d-31        [32, 2, 64, 64, 64]               0\n",
      "       BasicBlock-32        [32, 2, 64, 64, 64]               0\n",
      "       mem_update-33        [32, 2, 64, 64, 64]               0\n",
      "       Snn_Conv2d-34        [32, 2, 64, 64, 64]          36,864\n",
      "     BatchNorm3d1-35        [32, 64, 1, 64, 64]             128\n",
      "    batch_norm_2d-36        [32, 2, 64, 64, 64]               0\n",
      "       mem_update-37        [32, 2, 64, 64, 64]               0\n",
      "       Snn_Conv2d-38        [32, 2, 64, 64, 64]          36,864\n",
      "     BatchNorm3d2-39        [32, 64, 1, 64, 64]             128\n",
      "   batch_norm_2d1-40        [32, 2, 64, 64, 64]               0\n",
      "AdaptiveAvgPool3d-41          [32, 64, 1, 1, 1]               0\n",
      "           Conv3d-42           [32, 8, 1, 1, 1]             512\n",
      "             ReLU-43           [32, 8, 1, 1, 1]               0\n",
      "           Conv3d-44          [32, 64, 1, 1, 1]             512\n",
      "AdaptiveMaxPool3d-45          [32, 64, 1, 1, 1]               0\n",
      "           Conv3d-46           [32, 8, 1, 1, 1]             512\n",
      "             ReLU-47           [32, 8, 1, 1, 1]               0\n",
      "           Conv3d-48          [32, 64, 1, 1, 1]             512\n",
      "          Sigmoid-49          [32, 64, 1, 1, 1]               0\n",
      " ChannelAttention-50          [32, 1, 64, 1, 1]               0\n",
      "           Conv2d-51            [32, 1, 64, 64]              18\n",
      "          Sigmoid-52         [32, 1, 1, 64, 64]               0\n",
      " SpatialAttention-53         [32, 1, 1, 64, 64]               0\n",
      "             ReLU-54        [32, 1, 64, 64, 64]               0\n",
      "              CSA-55        [32, 1, 64, 64, 64]               0\n",
      "      PruningCell-56        [32, 2, 64, 64, 64]               0\n",
      "       BasicBlock-57        [32, 2, 64, 64, 64]               0\n",
      "       mem_update-58        [32, 2, 64, 64, 64]               0\n",
      "       Snn_Conv2d-59        [32, 2, 64, 64, 64]          36,864\n",
      "     BatchNorm3d1-60        [32, 64, 1, 64, 64]             128\n",
      "    batch_norm_2d-61        [32, 2, 64, 64, 64]               0\n",
      "       mem_update-62        [32, 2, 64, 64, 64]               0\n",
      "       Snn_Conv2d-63        [32, 2, 64, 64, 64]          36,864\n",
      "     BatchNorm3d2-64        [32, 64, 1, 64, 64]             128\n",
      "   batch_norm_2d1-65        [32, 2, 64, 64, 64]               0\n",
      "AdaptiveAvgPool3d-66          [32, 64, 1, 1, 1]               0\n",
      "           Conv3d-67           [32, 8, 1, 1, 1]             512\n",
      "             ReLU-68           [32, 8, 1, 1, 1]               0\n",
      "           Conv3d-69          [32, 64, 1, 1, 1]             512\n",
      "AdaptiveMaxPool3d-70          [32, 64, 1, 1, 1]               0\n",
      "           Conv3d-71           [32, 8, 1, 1, 1]             512\n",
      "             ReLU-72           [32, 8, 1, 1, 1]               0\n",
      "           Conv3d-73          [32, 64, 1, 1, 1]             512\n",
      "          Sigmoid-74          [32, 64, 1, 1, 1]               0\n",
      " ChannelAttention-75          [32, 1, 64, 1, 1]               0\n",
      "           Conv2d-76            [32, 1, 64, 64]              18\n",
      "          Sigmoid-77         [32, 1, 1, 64, 64]               0\n",
      " SpatialAttention-78         [32, 1, 1, 64, 64]               0\n",
      "             ReLU-79        [32, 1, 64, 64, 64]               0\n",
      "              CSA-80        [32, 1, 64, 64, 64]               0\n",
      "      PruningCell-81        [32, 2, 64, 64, 64]               0\n",
      "       BasicBlock-82        [32, 2, 64, 64, 64]               0\n",
      "       mem_update-83        [32, 2, 64, 64, 64]               0\n",
      "       Snn_Conv2d-84       [32, 2, 128, 32, 32]          73,728\n",
      "     BatchNorm3d1-85       [32, 128, 1, 32, 32]             256\n",
      "    batch_norm_2d-86       [32, 2, 128, 32, 32]               0\n",
      "       mem_update-87       [32, 2, 128, 32, 32]               0\n",
      "       Snn_Conv2d-88       [32, 2, 128, 32, 32]         147,456\n",
      "     BatchNorm3d2-89       [32, 128, 1, 32, 32]             256\n",
      "   batch_norm_2d1-90       [32, 2, 128, 32, 32]               0\n",
      "AdaptiveAvgPool3d-91         [32, 128, 1, 1, 1]               0\n",
      "           Conv3d-92          [32, 16, 1, 1, 1]           2,048\n",
      "             ReLU-93          [32, 16, 1, 1, 1]               0\n",
      "           Conv3d-94         [32, 128, 1, 1, 1]           2,048\n",
      "AdaptiveMaxPool3d-95         [32, 128, 1, 1, 1]               0\n",
      "           Conv3d-96          [32, 16, 1, 1, 1]           2,048\n",
      "             ReLU-97          [32, 16, 1, 1, 1]               0\n",
      "           Conv3d-98         [32, 128, 1, 1, 1]           2,048\n",
      "          Sigmoid-99         [32, 128, 1, 1, 1]               0\n",
      "ChannelAttention-100         [32, 1, 128, 1, 1]               0\n",
      "          Conv2d-101            [32, 1, 32, 32]              18\n",
      "         Sigmoid-102         [32, 1, 1, 32, 32]               0\n",
      "SpatialAttention-103         [32, 1, 1, 32, 32]               0\n",
      "            ReLU-104       [32, 1, 128, 32, 32]               0\n",
      "             CSA-105       [32, 1, 128, 32, 32]               0\n",
      "     PruningCell-106       [32, 2, 128, 32, 32]               0\n",
      "       AvgPool3d-107        [32, 2, 64, 32, 32]               0\n",
      "      Snn_Conv2d-108       [32, 2, 128, 32, 32]           8,192\n",
      "    BatchNorm3d1-109       [32, 128, 1, 32, 32]             256\n",
      "   batch_norm_2d-110       [32, 2, 128, 32, 32]               0\n",
      "      BasicBlock-111       [32, 2, 128, 32, 32]               0\n",
      "      mem_update-112       [32, 2, 128, 32, 32]               0\n",
      "      Snn_Conv2d-113       [32, 2, 128, 32, 32]         147,456\n",
      "    BatchNorm3d1-114       [32, 128, 1, 32, 32]             256\n",
      "   batch_norm_2d-115       [32, 2, 128, 32, 32]               0\n",
      "      mem_update-116       [32, 2, 128, 32, 32]               0\n",
      "      Snn_Conv2d-117       [32, 2, 128, 32, 32]         147,456\n",
      "    BatchNorm3d2-118       [32, 128, 1, 32, 32]             256\n",
      "  batch_norm_2d1-119       [32, 2, 128, 32, 32]               0\n",
      "AdaptiveAvgPool3d-120         [32, 128, 1, 1, 1]               0\n",
      "          Conv3d-121          [32, 16, 1, 1, 1]           2,048\n",
      "            ReLU-122          [32, 16, 1, 1, 1]               0\n",
      "          Conv3d-123         [32, 128, 1, 1, 1]           2,048\n",
      "AdaptiveMaxPool3d-124         [32, 128, 1, 1, 1]               0\n",
      "          Conv3d-125          [32, 16, 1, 1, 1]           2,048\n",
      "            ReLU-126          [32, 16, 1, 1, 1]               0\n",
      "          Conv3d-127         [32, 128, 1, 1, 1]           2,048\n",
      "         Sigmoid-128         [32, 128, 1, 1, 1]               0\n",
      "ChannelAttention-129         [32, 1, 128, 1, 1]               0\n",
      "          Conv2d-130            [32, 1, 32, 32]              18\n",
      "         Sigmoid-131         [32, 1, 1, 32, 32]               0\n",
      "SpatialAttention-132         [32, 1, 1, 32, 32]               0\n",
      "            ReLU-133       [32, 1, 128, 32, 32]               0\n",
      "             CSA-134       [32, 1, 128, 32, 32]               0\n",
      "     PruningCell-135       [32, 2, 128, 32, 32]               0\n",
      "      BasicBlock-136       [32, 2, 128, 32, 32]               0\n",
      "      mem_update-137       [32, 2, 128, 32, 32]               0\n",
      "      Snn_Conv2d-138       [32, 2, 128, 32, 32]         147,456\n",
      "    BatchNorm3d1-139       [32, 128, 1, 32, 32]             256\n",
      "   batch_norm_2d-140       [32, 2, 128, 32, 32]               0\n",
      "      mem_update-141       [32, 2, 128, 32, 32]               0\n",
      "      Snn_Conv2d-142       [32, 2, 128, 32, 32]         147,456\n",
      "    BatchNorm3d2-143       [32, 128, 1, 32, 32]             256\n",
      "  batch_norm_2d1-144       [32, 2, 128, 32, 32]               0\n",
      "AdaptiveAvgPool3d-145         [32, 128, 1, 1, 1]               0\n",
      "          Conv3d-146          [32, 16, 1, 1, 1]           2,048\n",
      "            ReLU-147          [32, 16, 1, 1, 1]               0\n",
      "          Conv3d-148         [32, 128, 1, 1, 1]           2,048\n",
      "AdaptiveMaxPool3d-149         [32, 128, 1, 1, 1]               0\n",
      "          Conv3d-150          [32, 16, 1, 1, 1]           2,048\n",
      "            ReLU-151          [32, 16, 1, 1, 1]               0\n",
      "          Conv3d-152         [32, 128, 1, 1, 1]           2,048\n",
      "         Sigmoid-153         [32, 128, 1, 1, 1]               0\n",
      "ChannelAttention-154         [32, 1, 128, 1, 1]               0\n",
      "          Conv2d-155            [32, 1, 32, 32]              18\n",
      "         Sigmoid-156         [32, 1, 1, 32, 32]               0\n",
      "SpatialAttention-157         [32, 1, 1, 32, 32]               0\n",
      "            ReLU-158       [32, 1, 128, 32, 32]               0\n",
      "             CSA-159       [32, 1, 128, 32, 32]               0\n",
      "     PruningCell-160       [32, 2, 128, 32, 32]               0\n",
      "      BasicBlock-161       [32, 2, 128, 32, 32]               0\n",
      "      mem_update-162       [32, 2, 128, 32, 32]               0\n",
      "      Snn_Conv2d-163       [32, 2, 128, 32, 32]         147,456\n",
      "    BatchNorm3d1-164       [32, 128, 1, 32, 32]             256\n",
      "   batch_norm_2d-165       [32, 2, 128, 32, 32]               0\n",
      "      mem_update-166       [32, 2, 128, 32, 32]               0\n",
      "      Snn_Conv2d-167       [32, 2, 128, 32, 32]         147,456\n",
      "    BatchNorm3d2-168       [32, 128, 1, 32, 32]             256\n",
      "  batch_norm_2d1-169       [32, 2, 128, 32, 32]               0\n",
      "AdaptiveAvgPool3d-170         [32, 128, 1, 1, 1]               0\n",
      "          Conv3d-171          [32, 16, 1, 1, 1]           2,048\n",
      "            ReLU-172          [32, 16, 1, 1, 1]               0\n",
      "          Conv3d-173         [32, 128, 1, 1, 1]           2,048\n",
      "AdaptiveMaxPool3d-174         [32, 128, 1, 1, 1]               0\n",
      "          Conv3d-175          [32, 16, 1, 1, 1]           2,048\n",
      "            ReLU-176          [32, 16, 1, 1, 1]               0\n",
      "          Conv3d-177         [32, 128, 1, 1, 1]           2,048\n",
      "         Sigmoid-178         [32, 128, 1, 1, 1]               0\n",
      "ChannelAttention-179         [32, 1, 128, 1, 1]               0\n",
      "          Conv2d-180            [32, 1, 32, 32]              18\n",
      "         Sigmoid-181         [32, 1, 1, 32, 32]               0\n",
      "SpatialAttention-182         [32, 1, 1, 32, 32]               0\n",
      "            ReLU-183       [32, 1, 128, 32, 32]               0\n",
      "             CSA-184       [32, 1, 128, 32, 32]               0\n",
      "     PruningCell-185       [32, 2, 128, 32, 32]               0\n",
      "      BasicBlock-186       [32, 2, 128, 32, 32]               0\n",
      "      mem_update-187       [32, 2, 128, 32, 32]               0\n",
      "      Snn_Conv2d-188       [32, 2, 256, 16, 16]         294,912\n",
      "    BatchNorm3d1-189       [32, 256, 1, 16, 16]             512\n",
      "   batch_norm_2d-190       [32, 2, 256, 16, 16]               0\n",
      "      mem_update-191       [32, 2, 256, 16, 16]               0\n",
      "      Snn_Conv2d-192       [32, 2, 256, 16, 16]         589,824\n",
      "    BatchNorm3d2-193       [32, 256, 1, 16, 16]             512\n",
      "  batch_norm_2d1-194       [32, 2, 256, 16, 16]               0\n",
      "AdaptiveAvgPool3d-195         [32, 256, 1, 1, 1]               0\n",
      "          Conv3d-196          [32, 32, 1, 1, 1]           8,192\n",
      "            ReLU-197          [32, 32, 1, 1, 1]               0\n",
      "          Conv3d-198         [32, 256, 1, 1, 1]           8,192\n",
      "AdaptiveMaxPool3d-199         [32, 256, 1, 1, 1]               0\n",
      "          Conv3d-200          [32, 32, 1, 1, 1]           8,192\n",
      "            ReLU-201          [32, 32, 1, 1, 1]               0\n",
      "          Conv3d-202         [32, 256, 1, 1, 1]           8,192\n",
      "         Sigmoid-203         [32, 256, 1, 1, 1]               0\n",
      "ChannelAttention-204         [32, 1, 256, 1, 1]               0\n",
      "          Conv2d-205            [32, 1, 16, 16]              18\n",
      "         Sigmoid-206         [32, 1, 1, 16, 16]               0\n",
      "SpatialAttention-207         [32, 1, 1, 16, 16]               0\n",
      "            ReLU-208       [32, 1, 256, 16, 16]               0\n",
      "             CSA-209       [32, 1, 256, 16, 16]               0\n",
      "     PruningCell-210       [32, 2, 256, 16, 16]               0\n",
      "       AvgPool3d-211       [32, 2, 128, 16, 16]               0\n",
      "      Snn_Conv2d-212       [32, 2, 256, 16, 16]          32,768\n",
      "    BatchNorm3d1-213       [32, 256, 1, 16, 16]             512\n",
      "   batch_norm_2d-214       [32, 2, 256, 16, 16]               0\n",
      "      BasicBlock-215       [32, 2, 256, 16, 16]               0\n",
      "      mem_update-216       [32, 2, 256, 16, 16]               0\n",
      "      Snn_Conv2d-217       [32, 2, 256, 16, 16]         589,824\n",
      "    BatchNorm3d1-218       [32, 256, 1, 16, 16]             512\n",
      "   batch_norm_2d-219       [32, 2, 256, 16, 16]               0\n",
      "      mem_update-220       [32, 2, 256, 16, 16]               0\n",
      "      Snn_Conv2d-221       [32, 2, 256, 16, 16]         589,824\n",
      "    BatchNorm3d2-222       [32, 256, 1, 16, 16]             512\n",
      "  batch_norm_2d1-223       [32, 2, 256, 16, 16]               0\n",
      "AdaptiveAvgPool3d-224         [32, 256, 1, 1, 1]               0\n",
      "          Conv3d-225          [32, 32, 1, 1, 1]           8,192\n",
      "            ReLU-226          [32, 32, 1, 1, 1]               0\n",
      "          Conv3d-227         [32, 256, 1, 1, 1]           8,192\n",
      "AdaptiveMaxPool3d-228         [32, 256, 1, 1, 1]               0\n",
      "          Conv3d-229          [32, 32, 1, 1, 1]           8,192\n",
      "            ReLU-230          [32, 32, 1, 1, 1]               0\n",
      "          Conv3d-231         [32, 256, 1, 1, 1]           8,192\n",
      "         Sigmoid-232         [32, 256, 1, 1, 1]               0\n",
      "ChannelAttention-233         [32, 1, 256, 1, 1]               0\n",
      "          Conv2d-234            [32, 1, 16, 16]              18\n",
      "         Sigmoid-235         [32, 1, 1, 16, 16]               0\n",
      "SpatialAttention-236         [32, 1, 1, 16, 16]               0\n",
      "            ReLU-237       [32, 1, 256, 16, 16]               0\n",
      "             CSA-238       [32, 1, 256, 16, 16]               0\n",
      "     PruningCell-239       [32, 2, 256, 16, 16]               0\n",
      "      BasicBlock-240       [32, 2, 256, 16, 16]               0\n",
      "      mem_update-241       [32, 2, 256, 16, 16]               0\n",
      "      Snn_Conv2d-242       [32, 2, 256, 16, 16]         589,824\n",
      "    BatchNorm3d1-243       [32, 256, 1, 16, 16]             512\n",
      "   batch_norm_2d-244       [32, 2, 256, 16, 16]               0\n",
      "      mem_update-245       [32, 2, 256, 16, 16]               0\n",
      "      Snn_Conv2d-246       [32, 2, 256, 16, 16]         589,824\n",
      "    BatchNorm3d2-247       [32, 256, 1, 16, 16]             512\n",
      "  batch_norm_2d1-248       [32, 2, 256, 16, 16]               0\n",
      "AdaptiveAvgPool3d-249         [32, 256, 1, 1, 1]               0\n",
      "          Conv3d-250          [32, 32, 1, 1, 1]           8,192\n",
      "            ReLU-251          [32, 32, 1, 1, 1]               0\n",
      "          Conv3d-252         [32, 256, 1, 1, 1]           8,192\n",
      "AdaptiveMaxPool3d-253         [32, 256, 1, 1, 1]               0\n",
      "          Conv3d-254          [32, 32, 1, 1, 1]           8,192\n",
      "            ReLU-255          [32, 32, 1, 1, 1]               0\n",
      "          Conv3d-256         [32, 256, 1, 1, 1]           8,192\n",
      "         Sigmoid-257         [32, 256, 1, 1, 1]               0\n",
      "ChannelAttention-258         [32, 1, 256, 1, 1]               0\n",
      "          Conv2d-259            [32, 1, 16, 16]              18\n",
      "         Sigmoid-260         [32, 1, 1, 16, 16]               0\n",
      "SpatialAttention-261         [32, 1, 1, 16, 16]               0\n",
      "            ReLU-262       [32, 1, 256, 16, 16]               0\n",
      "             CSA-263       [32, 1, 256, 16, 16]               0\n",
      "     PruningCell-264       [32, 2, 256, 16, 16]               0\n",
      "      BasicBlock-265       [32, 2, 256, 16, 16]               0\n",
      "      mem_update-266       [32, 2, 256, 16, 16]               0\n",
      "      Snn_Conv2d-267       [32, 2, 256, 16, 16]         589,824\n",
      "    BatchNorm3d1-268       [32, 256, 1, 16, 16]             512\n",
      "   batch_norm_2d-269       [32, 2, 256, 16, 16]               0\n",
      "      mem_update-270       [32, 2, 256, 16, 16]               0\n",
      "      Snn_Conv2d-271       [32, 2, 256, 16, 16]         589,824\n",
      "    BatchNorm3d2-272       [32, 256, 1, 16, 16]             512\n",
      "  batch_norm_2d1-273       [32, 2, 256, 16, 16]               0\n",
      "AdaptiveAvgPool3d-274         [32, 256, 1, 1, 1]               0\n",
      "          Conv3d-275          [32, 32, 1, 1, 1]           8,192\n",
      "            ReLU-276          [32, 32, 1, 1, 1]               0\n",
      "          Conv3d-277         [32, 256, 1, 1, 1]           8,192\n",
      "AdaptiveMaxPool3d-278         [32, 256, 1, 1, 1]               0\n",
      "          Conv3d-279          [32, 32, 1, 1, 1]           8,192\n",
      "            ReLU-280          [32, 32, 1, 1, 1]               0\n",
      "          Conv3d-281         [32, 256, 1, 1, 1]           8,192\n",
      "         Sigmoid-282         [32, 256, 1, 1, 1]               0\n",
      "ChannelAttention-283         [32, 1, 256, 1, 1]               0\n",
      "          Conv2d-284            [32, 1, 16, 16]              18\n",
      "         Sigmoid-285         [32, 1, 1, 16, 16]               0\n",
      "SpatialAttention-286         [32, 1, 1, 16, 16]               0\n",
      "            ReLU-287       [32, 1, 256, 16, 16]               0\n",
      "             CSA-288       [32, 1, 256, 16, 16]               0\n",
      "     PruningCell-289       [32, 2, 256, 16, 16]               0\n",
      "      BasicBlock-290       [32, 2, 256, 16, 16]               0\n",
      "      mem_update-291       [32, 2, 256, 16, 16]               0\n",
      "      Snn_Conv2d-292       [32, 2, 256, 16, 16]         589,824\n",
      "    BatchNorm3d1-293       [32, 256, 1, 16, 16]             512\n",
      "   batch_norm_2d-294       [32, 2, 256, 16, 16]               0\n",
      "      mem_update-295       [32, 2, 256, 16, 16]               0\n",
      "      Snn_Conv2d-296       [32, 2, 256, 16, 16]         589,824\n",
      "    BatchNorm3d2-297       [32, 256, 1, 16, 16]             512\n",
      "  batch_norm_2d1-298       [32, 2, 256, 16, 16]               0\n",
      "AdaptiveAvgPool3d-299         [32, 256, 1, 1, 1]               0\n",
      "          Conv3d-300          [32, 32, 1, 1, 1]           8,192\n",
      "            ReLU-301          [32, 32, 1, 1, 1]               0\n",
      "          Conv3d-302         [32, 256, 1, 1, 1]           8,192\n",
      "AdaptiveMaxPool3d-303         [32, 256, 1, 1, 1]               0\n",
      "          Conv3d-304          [32, 32, 1, 1, 1]           8,192\n",
      "            ReLU-305          [32, 32, 1, 1, 1]               0\n",
      "          Conv3d-306         [32, 256, 1, 1, 1]           8,192\n",
      "         Sigmoid-307         [32, 256, 1, 1, 1]               0\n",
      "ChannelAttention-308         [32, 1, 256, 1, 1]               0\n",
      "          Conv2d-309            [32, 1, 16, 16]              18\n",
      "         Sigmoid-310         [32, 1, 1, 16, 16]               0\n",
      "SpatialAttention-311         [32, 1, 1, 16, 16]               0\n",
      "            ReLU-312       [32, 1, 256, 16, 16]               0\n",
      "             CSA-313       [32, 1, 256, 16, 16]               0\n",
      "     PruningCell-314       [32, 2, 256, 16, 16]               0\n",
      "      BasicBlock-315       [32, 2, 256, 16, 16]               0\n",
      "      mem_update-316       [32, 2, 256, 16, 16]               0\n",
      "      Snn_Conv2d-317       [32, 2, 256, 16, 16]         589,824\n",
      "    BatchNorm3d1-318       [32, 256, 1, 16, 16]             512\n",
      "   batch_norm_2d-319       [32, 2, 256, 16, 16]               0\n",
      "      mem_update-320       [32, 2, 256, 16, 16]               0\n",
      "      Snn_Conv2d-321       [32, 2, 256, 16, 16]         589,824\n",
      "    BatchNorm3d2-322       [32, 256, 1, 16, 16]             512\n",
      "  batch_norm_2d1-323       [32, 2, 256, 16, 16]               0\n",
      "AdaptiveAvgPool3d-324         [32, 256, 1, 1, 1]               0\n",
      "          Conv3d-325          [32, 32, 1, 1, 1]           8,192\n",
      "            ReLU-326          [32, 32, 1, 1, 1]               0\n",
      "          Conv3d-327         [32, 256, 1, 1, 1]           8,192\n",
      "AdaptiveMaxPool3d-328         [32, 256, 1, 1, 1]               0\n",
      "          Conv3d-329          [32, 32, 1, 1, 1]           8,192\n",
      "            ReLU-330          [32, 32, 1, 1, 1]               0\n",
      "          Conv3d-331         [32, 256, 1, 1, 1]           8,192\n",
      "         Sigmoid-332         [32, 256, 1, 1, 1]               0\n",
      "ChannelAttention-333         [32, 1, 256, 1, 1]               0\n",
      "          Conv2d-334            [32, 1, 16, 16]              18\n",
      "         Sigmoid-335         [32, 1, 1, 16, 16]               0\n",
      "SpatialAttention-336         [32, 1, 1, 16, 16]               0\n",
      "            ReLU-337       [32, 1, 256, 16, 16]               0\n",
      "             CSA-338       [32, 1, 256, 16, 16]               0\n",
      "     PruningCell-339       [32, 2, 256, 16, 16]               0\n",
      "      BasicBlock-340       [32, 2, 256, 16, 16]               0\n",
      "      mem_update-341       [32, 2, 256, 16, 16]               0\n",
      "      Snn_Conv2d-342         [32, 2, 512, 8, 8]       1,179,648\n",
      "    BatchNorm3d1-343         [32, 512, 1, 8, 8]           1,024\n",
      "   batch_norm_2d-344         [32, 2, 512, 8, 8]               0\n",
      "      mem_update-345         [32, 2, 512, 8, 8]               0\n",
      "      Snn_Conv2d-346         [32, 2, 512, 8, 8]       2,359,296\n",
      "    BatchNorm3d2-347         [32, 512, 1, 8, 8]           1,024\n",
      "  batch_norm_2d1-348         [32, 2, 512, 8, 8]               0\n",
      "AdaptiveAvgPool3d-349         [32, 512, 1, 1, 1]               0\n",
      "          Conv3d-350          [32, 64, 1, 1, 1]          32,768\n",
      "            ReLU-351          [32, 64, 1, 1, 1]               0\n",
      "          Conv3d-352         [32, 512, 1, 1, 1]          32,768\n",
      "AdaptiveMaxPool3d-353         [32, 512, 1, 1, 1]               0\n",
      "          Conv3d-354          [32, 64, 1, 1, 1]          32,768\n",
      "            ReLU-355          [32, 64, 1, 1, 1]               0\n",
      "          Conv3d-356         [32, 512, 1, 1, 1]          32,768\n",
      "         Sigmoid-357         [32, 512, 1, 1, 1]               0\n",
      "ChannelAttention-358         [32, 1, 512, 1, 1]               0\n",
      "          Conv2d-359              [32, 1, 8, 8]              18\n",
      "         Sigmoid-360           [32, 1, 1, 8, 8]               0\n",
      "SpatialAttention-361           [32, 1, 1, 8, 8]               0\n",
      "            ReLU-362         [32, 1, 512, 8, 8]               0\n",
      "             CSA-363         [32, 1, 512, 8, 8]               0\n",
      "     PruningCell-364         [32, 2, 512, 8, 8]               0\n",
      "       AvgPool3d-365         [32, 2, 256, 8, 8]               0\n",
      "      Snn_Conv2d-366         [32, 2, 512, 8, 8]         131,072\n",
      "    BatchNorm3d1-367         [32, 512, 1, 8, 8]           1,024\n",
      "   batch_norm_2d-368         [32, 2, 512, 8, 8]               0\n",
      "      BasicBlock-369         [32, 2, 512, 8, 8]               0\n",
      "      mem_update-370         [32, 2, 512, 8, 8]               0\n",
      "      Snn_Conv2d-371         [32, 2, 512, 8, 8]       2,359,296\n",
      "    BatchNorm3d1-372         [32, 512, 1, 8, 8]           1,024\n",
      "   batch_norm_2d-373         [32, 2, 512, 8, 8]               0\n",
      "      mem_update-374         [32, 2, 512, 8, 8]               0\n",
      "      Snn_Conv2d-375         [32, 2, 512, 8, 8]       2,359,296\n",
      "    BatchNorm3d2-376         [32, 512, 1, 8, 8]           1,024\n",
      "  batch_norm_2d1-377         [32, 2, 512, 8, 8]               0\n",
      "AdaptiveAvgPool3d-378         [32, 512, 1, 1, 1]               0\n",
      "          Conv3d-379          [32, 64, 1, 1, 1]          32,768\n",
      "            ReLU-380          [32, 64, 1, 1, 1]               0\n",
      "          Conv3d-381         [32, 512, 1, 1, 1]          32,768\n",
      "AdaptiveMaxPool3d-382         [32, 512, 1, 1, 1]               0\n",
      "          Conv3d-383          [32, 64, 1, 1, 1]          32,768\n",
      "            ReLU-384          [32, 64, 1, 1, 1]               0\n",
      "          Conv3d-385         [32, 512, 1, 1, 1]          32,768\n",
      "         Sigmoid-386         [32, 512, 1, 1, 1]               0\n",
      "ChannelAttention-387         [32, 1, 512, 1, 1]               0\n",
      "          Conv2d-388              [32, 1, 8, 8]              18\n",
      "         Sigmoid-389           [32, 1, 1, 8, 8]               0\n",
      "SpatialAttention-390           [32, 1, 1, 8, 8]               0\n",
      "            ReLU-391         [32, 1, 512, 8, 8]               0\n",
      "             CSA-392         [32, 1, 512, 8, 8]               0\n",
      "     PruningCell-393         [32, 2, 512, 8, 8]               0\n",
      "      BasicBlock-394         [32, 2, 512, 8, 8]               0\n",
      "      mem_update-395         [32, 2, 512, 8, 8]               0\n",
      "      Snn_Conv2d-396         [32, 2, 512, 8, 8]       2,359,296\n",
      "    BatchNorm3d1-397         [32, 512, 1, 8, 8]           1,024\n",
      "   batch_norm_2d-398         [32, 2, 512, 8, 8]               0\n",
      "      mem_update-399         [32, 2, 512, 8, 8]               0\n",
      "      Snn_Conv2d-400         [32, 2, 512, 8, 8]       2,359,296\n",
      "    BatchNorm3d2-401         [32, 512, 1, 8, 8]           1,024\n",
      "  batch_norm_2d1-402         [32, 2, 512, 8, 8]               0\n",
      "AdaptiveAvgPool3d-403         [32, 512, 1, 1, 1]               0\n",
      "          Conv3d-404          [32, 64, 1, 1, 1]          32,768\n",
      "            ReLU-405          [32, 64, 1, 1, 1]               0\n",
      "          Conv3d-406         [32, 512, 1, 1, 1]          32,768\n",
      "AdaptiveMaxPool3d-407         [32, 512, 1, 1, 1]               0\n",
      "          Conv3d-408          [32, 64, 1, 1, 1]          32,768\n",
      "            ReLU-409          [32, 64, 1, 1, 1]               0\n",
      "          Conv3d-410         [32, 512, 1, 1, 1]          32,768\n",
      "         Sigmoid-411         [32, 512, 1, 1, 1]               0\n",
      "ChannelAttention-412         [32, 1, 512, 1, 1]               0\n",
      "          Conv2d-413              [32, 1, 8, 8]              18\n",
      "         Sigmoid-414           [32, 1, 1, 8, 8]               0\n",
      "SpatialAttention-415           [32, 1, 1, 8, 8]               0\n",
      "            ReLU-416         [32, 1, 512, 8, 8]               0\n",
      "             CSA-417         [32, 1, 512, 8, 8]               0\n",
      "     PruningCell-418         [32, 2, 512, 8, 8]               0\n",
      "      BasicBlock-419         [32, 2, 512, 8, 8]               0\n",
      "      mem_update-420         [32, 2, 512, 8, 8]               0\n",
      "      mem_update-421         [32, 2, 512, 8, 8]               0\n",
      "      Snn_Conv2d-422         [32, 2, 256, 8, 8]       1,179,648\n",
      "    BatchNorm3d1-423         [32, 256, 1, 8, 8]             512\n",
      "   batch_norm_2d-424         [32, 2, 256, 8, 8]               0\n",
      "TimeDistributedUpsample-425       [32, 2, 256, 16, 16]               0\n",
      "      mem_update-426       [32, 2, 256, 16, 16]               0\n",
      "      Snn_Conv2d-427       [32, 2, 128, 16, 16]         294,912\n",
      "    BatchNorm3d1-428       [32, 128, 1, 16, 16]             256\n",
      "   batch_norm_2d-429       [32, 2, 128, 16, 16]               0\n",
      "TimeDistributedUpsample-430       [32, 2, 128, 32, 32]               0\n",
      "      mem_update-431       [32, 2, 128, 32, 32]               0\n",
      "      Snn_Conv2d-432        [32, 2, 64, 32, 32]          73,728\n",
      "    BatchNorm3d1-433        [32, 64, 1, 32, 32]             128\n",
      "   batch_norm_2d-434        [32, 2, 64, 32, 32]               0\n",
      "TimeDistributedUpsample-435        [32, 2, 64, 64, 64]               0\n",
      "      mem_update-436        [32, 2, 64, 64, 64]               0\n",
      "      Snn_Conv2d-437        [32, 2, 32, 64, 64]          18,432\n",
      "    BatchNorm3d1-438        [32, 32, 1, 64, 64]              64\n",
      "   batch_norm_2d-439        [32, 2, 32, 64, 64]               0\n",
      "TimeDistributedUpsample-440      [32, 2, 32, 128, 128]               0\n",
      "      mem_update-441      [32, 2, 32, 128, 128]               0\n",
      "      Snn_Conv2d-442      [32, 2, 16, 128, 128]           4,608\n",
      "    BatchNorm3d1-443      [32, 16, 1, 128, 128]              32\n",
      "   batch_norm_2d-444      [32, 2, 16, 128, 128]               0\n",
      "TimeDistributedUpsample-445      [32, 2, 16, 256, 256]               0\n",
      "      mem_update-446      [32, 2, 16, 256, 256]               0\n",
      "      Snn_Conv2d-447       [32, 2, 1, 256, 256]              16\n",
      "    BatchNorm3d1-448       [32, 1, 1, 256, 256]               2\n",
      "   batch_norm_2d-449       [32, 2, 1, 256, 256]               0\n",
      "SpikingSegmentationLayer-450          [32, 1, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 23,483,986\n",
      "Trainable params: 23,483,986\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 8.00\n",
      "Forward/backward pass size (MB): 14111.26\n",
      "Params size (MB): 89.58\n",
      "Estimated Total Size (MB): 14208.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1, 256, 256), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2551790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR      =  \"/kaggle/input/braindataset/Modified_3_Brain_Tumor_Segmentation/images\"\n",
    "MASK_DIR     =  \"/kaggle/input/braindataset/Modified_3_Brain_Tumor_Segmentation/masks\"\n",
    "VAL_IMG_DIR  =  \"/kaggle/input/braindataset/Modified_3_Brain_Tumor_Segmentation/val_images\"\n",
    "VAL_MASK_DIR =  \"/kaggle/input/braindataset/Modified_3_Brain_Tumor_Segmentation/val_masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d822dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "Learning_rate = 1e-3\n",
    "Batch_size  = 32\n",
    "num_epochs  = 60\n",
    "num_workers = 4\n",
    "IMAGE_HEIGHT = 256 \n",
    "IMAGE_WIDTH  = 256  \n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "CHECKPOINT_NAME = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec65d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-8):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)\n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "929a5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, dice_loss_fn, scaler):\n",
    "\n",
    "    tracker = Tracker(\n",
    "        project_name=\"attentionSNN_Training_Project\",\n",
    "        experiment_description=\"Training CSA Spiking Upsampling Layer Model\",\n",
    "        file_name=\"attentionSNN_eco2ai_logs.csv\",\n",
    "        alpha_2_code=\"EG\",  \n",
    "    )\n",
    "    tracker.start()\n",
    "\n",
    "    loop = tqdm(loader)\n",
    "    running_loss=0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=Device)\n",
    "        targets = targets.float().unsqueeze(1).to(device=Device) \n",
    "\n",
    "        with torch.amp.autocast(device_type=Device):\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "            # dice_loss = dice_loss_fn(predictions, targets)\n",
    "            # loss += dice_loss  # Combined hybrid loss\n",
    "        \n",
    "        running_loss+=loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    tracker.stop()\n",
    "\n",
    "    nasar = model.calculate_nasar()\n",
    "    \n",
    "    return running_loss/len(loader), nasar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "776f1658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Rotate(limit=35, p=1.0),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.1),\n",
    "            A.Normalize(\n",
    "                mean=[0.0],\n",
    "                std=[1.0],\n",
    "                max_pixel_value=255.0,\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "    val_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Normalize(\n",
    "                mean=[0.0],\n",
    "                std=[1.0],\n",
    "                max_pixel_value=255.0,\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "    model = resnet_2.resnet34().to(device)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    dice_loss_fn = DiceLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=Learning_rate)\n",
    "    # scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "    # scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)  \n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "    train_loader, val_loader = get_loaders(\n",
    "        IMG_DIR,\n",
    "        MASK_DIR,\n",
    "        VAL_IMG_DIR,\n",
    "        VAL_MASK_DIR,\n",
    "        Batch_size,\n",
    "        train_transform,\n",
    "        val_transform,\n",
    "        num_workers,\n",
    "        PIN_MEMORY,\n",
    "    )\n",
    "\n",
    "    train_losses=[]\n",
    "    val_dice_scores=[]\n",
    "    val_accs=[]\n",
    "    train_nasar=[]\n",
    "\n",
    "    if LOAD_MODEL:\n",
    "        load_checkpoint(model=model, optimizer=optimizer, checkpoint_name=CHECKPOINT_NAME)\n",
    "        val_acc_loaded, val_dice_loaded = check_accuracy(val_loader, model, device=Device)\n",
    "\n",
    "    scaler = torch.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_fn(train_loader, model, optimizer, loss_fn, dice_loss_fn, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "693d6caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75bb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_eco2ai_log(\"attentionSNN_eco2ai_logs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
